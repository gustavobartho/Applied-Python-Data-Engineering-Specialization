{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/home/user/.application-data/spark\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'notebook'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/18 21:43:39 WARN Utils: Your hostname, user-PC resolves to a loopback address: 127.0.1.1; using 192.168.0.27 instead (on interface wlp3s0)\n",
      "24/09/18 21:43:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/18 21:43:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession.builder.appName('pyspark-intro').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_number: string, aba: string, bic: string, opened: string, balance: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file into DataFrame\n",
    "accounts = spark.read.option('header', True).csv('../data/accounts.csv')\n",
    "accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_number: string (nullable = true)\n",
      " |-- aba: string (nullable = true)\n",
      " |-- bic: string (nullable = true)\n",
      " |-- opened: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/18 21:43:52 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Print DF schema\n",
    "accounts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_number: string (nullable = true)\n",
      " |-- amount: long (nullable = true)\n",
      " |-- datetime: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read from parquet\n",
    "transactions = spark.read.option('header', True).parquet('../data/transactions.parquet')\n",
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of records\n",
    "transactions.count(), accounts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sums the total amount in each account\n",
    "account_transactions = transactions.groupby('account_number').sum()\n",
    "# inner joins the totals with the accounts by account_number col\n",
    "with_sum = accounts.join(account_transactions, 'account_number', 'inner')\n",
    "# takes the DF with the sum, creating a new col named new_balance and setting its value as the sum of the initial ballance and the sum(amount) col (col created in the groupby)\n",
    "accounts = with_sum.withColumn('new_balance', sum([with_sum.balance, with_sum['sum(amount)']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_number: string (nullable = true)\n",
      " |-- aba: string (nullable = true)\n",
      " |-- bic: string (nullable = true)\n",
      " |-- opened: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- sum(amount): long (nullable = true)\n",
      " |-- new_balance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accounts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows by condition\n",
    "neg_balance = accounts.filter(accounts.new_balance < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_number: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clients = spark.read.json('../data/clients.json')\n",
    "clients.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_number: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- aba: string (nullable = true)\n",
      " |-- bic: string (nullable = true)\n",
      " |-- opened: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- sum(amount): long (nullable = true)\n",
      " |-- new_balance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gets customers with negative ballance\n",
    "clients = clients.join(neg_balance, 'account_number', 'inner')\n",
    "clients.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------------------+-----------+\n",
      "|first_name|last_name|    account_number|new_balance|\n",
      "+----------+---------+------------------+-----------+\n",
      "|    Meagan| Sandoval|JMTP45763117901514|   -27573.0|\n",
      "|  Michelle|   Knight|RBUE05237750254383|  -103459.0|\n",
      "|      Paul|   Massey|RJMY57096756148587|   -58329.0|\n",
      "|  Michelle|    Perez|ZYMB62177146259441|   -55431.0|\n",
      "|     David|    Green|LRTH65732611614073|  -103831.0|\n",
      "+----------+---------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# selects list of columns -> similar to SQL SELECT\n",
    "clients = clients.select(['first_name', 'last_name', 'account_number', 'new_balance'])\n",
    "# shown first N rows of clients\n",
    "clients.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
